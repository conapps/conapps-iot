| [< Anterior](.\20170807_AWS_S3.md) | [Siguiente >](.\AWS_S3_Parte_3.md) |



---
## Acerca de los datos
---

### S3 Storage Classes
Amazon S3 ofrece varios tipos de almacenamiento diseñados para distintos casos de uso:
* **Amazon S3 Standard**: almacenamiento de datos de uso general, a los que se accede en forma frecuente. Ofrece alta durabilidad, disponibilidad y desempeño, y baja latencia.
Casos de uso: aplicaciones en la nube, sitios web dinámicos, distribución de contenidos, aplicaciones móviles y de juegos, y el análisis de big data.

* **Amazon S3 Standard Acceso Poco Frecuente (Standad-IA)**: almacenamiento para datos de larga duración, a los que se accede con poca frecuencia, pero que requieren un acceso rápido cuando es necesario. Alta durabilidad, alto desempeño y baja latencia, con menor disponibilidad. Tiene costos asociados con la recuperación de datos por GB.
Casos de uso: almacenamiento a largo plazo, backups, almacén de datos para la recuperación de desastres.

* **Amazon S3 Reduced Redundancy (RSS)**: almacenamiento para datos de larga duración, a los que se accede con menos frecuencia, que no resulten de vital importancia y puedan ser reproducibles. Ofrece menor durabilidad, dado que no replica los objetos tantas veces como la clase Standard.
Casos de uso: distribución o el uso compartido de contenido que está almacenado de una forma resistente en cualquier otra ubicación o para el almacenamiento de miniaturas, contenido multimedia transcodificado o cualquier otro tipo de datos procesados que puedan reproducirse fácilmente.

* **Amazon Glacier**: para el archivado a largo plazo, a los cuales se accede en forma muy poco frecuente, dado que el acceso no es inmediato.
Tiene costos asociados con la recuperación de datos por GB. Proporciona tres opciones de acceso a los archivos, que van desde unos pocos minutos a varias horas, y diferentes costos.
Casos de uso: archivado (*archive*) de datos a largo plazo.

Refs:
* [Tipos de Almacenamiento de Amazon S3](https://aws.amazon.com/es/s3/storage-classes/)
* [Almacenamiento de redundancia reducida](https://aws.amazon.com/es/s3/reduced-redundancy/)


### Gestión del ciclo de vida de los datos
Amazon S3 ofrece políticas de Gestión del Ciclo de Vida que permiten transferir los datos en forma automática al tipo de almacenamiento más adecuado.


### Durabilidad y Disponibilidad
La durabilidad y disponibilidad de los datos son conceptos diferentes. La **durabilidad** responde a la pregunta *estarán mis datos ahí en el futuro?* Mientras que la **disponibilidad** refiere a la pregunta *puedo acceder a mis datos ahora mismo, o en cualquier momento?*

Amazon S3 ofrece diferentes niveles de disponibilidad y durabilidad, dependiendo del tipo de storage seleccionado (Storage Class).

*Amazon S3 Standard Storage* está diseñado para 99.999999999% de durabilidad y 99.99% de disponibilidad anual. Esto quiere decir, por ejemplo, que si tenemos 10.000 objetos, en promedio podríamos esperar tener una perdida de un único objeto cada 10.000.000 años.

Esto se logra dado que S3 replica automaticamente los datos entre múltiples dispositivos en diferentes ubicaciones dentro de una misma región. Está designado para perder soprota la perdida de datos hasta en dos ubicaciones sin ocacionar perdida real de datos al usuario final.   

### Consistencia de datos
Amazon S3 es un sistema *eventualmente consistente*. Dado que los datos son replicados automaticamente entre múltiples servidores y ubicaciones dentro de una región, los cambios en los datos pueden tomar cierto tiempo en propagarse a todas las ubicaciones. Por lo tanto, en ciertas ocaciones, algunas operaciones pueden devolver datos que no se encuentran actualizados.

Para PUTs a nuevos objetos, esto no es un problema, porque Amazon S3 provee consistencia *read-after-write*. Es decir, que si creamos un nuevo objeto y luego lo leemos, siempre vamos a obtener la última versión.

Sin embargo, para PUTs a objetos existentes (si sobreescribimos un objeto sobre una key existente) y para DELETEs, Amazon S3 provee *consistencia eventual*. Esto significa que si subimos (PUT) datos a una clave existente, y luego intentamos accederlos (GET), podría devolvernos la versión anterior de los datos.En forma similar, si borramos (DELETE) un objeto, y luego intentamos acceder al objeto (GET) podríamos todavía leer los datos del objeto eliminado.

En todos los casos las operaciones son atómicas, es decir, se obtiene el dato o no se obtiene, pero nunca obtendremos datos incosistentes.

Ref: [Amazon S3 Data Consistency Model](http://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel)


### Características de las diferentes clases de storage en S3
La siguiente tabla muestra las diferencias entre los diferentes tipos de *Storage Classes* en S3:
 ![alt text](./images/S3_sla.png)
 ![alt text](./images/S3_sla_glacier.png)


### Precio AWS S3
El precio de AWS S3 depende no solo de la clase de storage que utilicemos, sino también de la región que seleccionemos para nuestros *buckets*.

![alt text](./images/S3_price_us-west-2.png)

Algunas regiones pueden no tener ciertas capas de storage, por ej. en el caso de San Pablo (sa-east-1) podemos ver que *Glacier* no está disponible.
![alt text](./images/S3_price_sa-east-1.png)

Ref: [Precios de AWS S3](https://aws.amazon.com/es/s3/pricing/)


---
## Volvamos al práctico!
---
### Mover objetos entre S3 Storage Classes
Los objetos se pueden subir directamente a una determinada *Storage Class*.

Esto lo podemos hacer directamente por línea de comando:

```bash
$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
2017-08-10 21:11:11 iot-cloud-bucket-2

$ aws s3 cp documento1.txt s3://iot-cloud-bucket-2/ --storage-class REDUCED_REDUNDANCY
upload: .\documento1.txt to s3://iot-cloud-bucket-2/documento1.txt

$ aws s3 ls iot-cloud-bucket-2
2017-08-10 21:16:02         34 documento1.txt
```
En el ejemplo anterior estamos subiendo el objeto a la clase de *Reduced Redundancy Storage (RRS)*.
Podemos elegir donde subirlo utilizando las opciones *STANDARD*, *STANDARD_IA*, o *REDUCED_REDUNDANCY*.

Ref: [Sintaxis del comando *aws s3 cp*](http://docs.aws.amazon.com/cli/latest/reference/s3/cp.html)

Pero como sabemos en que clase de storage se encuentra este objeto?? Una opción sería invocando a la API de S3 (ya llegaremos a esto luego):
...
```bash
$ aws s3api list-objects --bucket iot-cloud-bucket-2
{
    "Contents": [
        {
            "Key": "documento1.txt",
            "LastModified": "2017-08-11T00:16:02.000Z",
            "ETag": "\"fb4794e7e7bfbffb4630114f236cc02d\"",
            "Size": 34,
            "StorageClass": "REDUCED_REDUNDANCY",
            "Owner": {
                "DisplayName": "fernando.agis",
                "ID": "253b01d45d66119b56bac9fdb06d91f8eb9d0aea9b7f4fbfea1ef963e189cf2d"
            }
        }
    ]
}
```
Mediante la consola web de AWS S3, también podemos especificar la clase de storage donde subimos el objeto:

![alt text](./images/S3_upload_05.png)
![alt text](./images/S3_upload_06.png)

Y ver a que clase de storage pertenece:
![alt text](./images/S3_upload_07.png)

También podemos cambiarle la *storage class* a un objeto que ya se encuentra en S3:

```bash
$ aws s3 cp s3://iot-cloud-bucket-2/documento1.txt s3://iot-cloud-bucket-2/documento1.txt --storage-class STANDARD
copy: s3://iot-cloud-bucket-2/documento1.txt to s3://iot-cloud-bucket-2/documento1.txt
```
Verifique en la consola web o por línea de comando que el objeto *documento1.txt* efectivamente se cambio a la clase de storage *STANDARD* (puede requerir un reload en la consola web).

Y por supuesto que la clase de storage se puede cambiar desde la propia consola web, seleccionando el objeto *documento2.txt* y modificando sus propiedades:

![alt text](./images/S3_object_01.png)
![alt text](./images/S3_object_02.png)
![alt text](./images/S3_object_03.png)

### Static Web Pages

### Throughput omptimisation

### Access Controls

### Encryption ###
* None
* Amazon S3 Master Key
* AWS KMS master-key



### Metadata ###
* Header / Value
