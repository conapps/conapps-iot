Amazon Simple Storage Service (Amazon S3)
===

*Fuentes:*
- [Documentación oficial](https://aws.amazon.com/es/documentation/s3/)
- [Página de AWS S3](https://aws.amazon.com/es/s3/)
- [Precios de AWS S3](http://aws.amazon.com/s3/pricing/)
- [AWS S3 Master Class](https://www.youtube.com/watch?v=VC0k-noNwOU)


## Indice.
---
- [Introducción](#introduccion)
- [Conceptos Básicos](#conceptos-básicos)
- [Primeros Pasos](#primeros-pasos)
- [Linea de Comandos de Amazon S3](#línea-de-comandos-de-amazon-s3)


---
## Introducción ##
---
¿Qué es Amazon S3?      
---
Amazon S3 es un **almacenamiento de objetos** creado para almacenar y recuperar cualquier cantidad de datos desde cualquier ubicación: sitios web y aplicaciones móviles, aplicaciones corporativas y datos de sensores o dispositivos IoT.

Permite recopilar, almacenar y analizar datos de forma cómoda y sencilla, independientemente de su formato y a escala masiva. Es durable, seguro, y altamente escalable. Puede ser accedido desde la interface web, desde la línea de comando (Amazon CLI) y/o desde APIs. Puede utilizarse en forma aislada como un repositorio de datos, o en forma integrada con otros servicios de AWS.

### Características
* Fácil de usar
* Bajo costo
* Disponible (cuatro 9s)
* Durable (once 9s)
* Seguro
* Escalable
* Integrado con otros servicios AWS

### Casos de uso
* Backup & Archive
* Almacenar y distribuir contenido (fotos, videos, etc.)
* Static Website Hosting
* Big Data & Analytics
* Almacenamiento de nube híbrida
* Datos de aplicaciones Cloud-native
* Distaster recovery

Para soportar estos tipos de uso, Amazon S3 ofrece diferentes tipos de storages (*Storage Classes*), designados para diferentes modalidades de uso: *General purpose*, *Infrequent access*, y *Archive*.

Para ayudar a gestionar los datos, cuenta con un gestor de políticas (*Lifecycle Policies*) que permite mover los datos en forma automática entre las diferentes clases de storage.

También provee seguridad, control de acceso, y encriptación.

### Object Storage vs Traditional Storage

Existen varias diferencias entre las soluciones de almacenamiento tradicional (Block Storage, File Sotage) y las soluciones de almacenamiento de objetos (Object Storage).

En el siguiente artículo se puede encontrar información adicional:

   * [Introduction To Object Storage](https://blog.rackspace.com/introduction-to-object-storage)

---
## Conceptos Básicos ##
---

### Buckets
Son los depósitos donde se almacenan los objetos en S3. Representan el nivel mas alto de jerarquía dentro del almacenamiento. Cada objeto encuentra dentro de un *bucket*.
Se pueden crear y utilizar hasta 100 *buckets* por cada cuenta por defecto, y cada *bucket* puede contener miles de objetos.
s
El nombre del *bucket* debe ser único dentro de todos los existentes en Amazon S3 (no solo dentro de mi cuenta). Debe cumplir con una serie de reglas, debe tener entre 3 y 63 caracteres, no puede tener mayúsculas, ni espacios, ni caracteres especiales salvo guiones y puntos, entre otros.  

El nombre del *bucket* será visible en la URL que remite a los objetos almacenados en él. Una vez creado, el nombre no puede ser modificado.

Referencias:
    [Working with Amazon S3 Buckets](http://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/UsingBucket.html)
    [Restricciones y limitaciones en los Buckets](http://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/BucketRestrictions.html)


### Objects
Son los objetos (archivos) almacenados en Amazon S3.
Un objeto puede contener cualquier tipo de datos en cualquier formato.
El tamaño máximo para un objeto es de 5TB, y un *bucket* puede contener una cantidad ilimitada de objetos.

Cada objeto consiste de *datos* (el archivo propiamente dicho) y *metadatos* (una serie de información acerca del archivo). La porción de *datos* es opaca a S3, es decir, es tratada como un simple conjunto de bytes sin importar su contenido. Los *metadatos* son pares de valores nombrados, que describen el objeto.

### Keys
Un objeto es identificado en forma única dentro de un *bucket* por una clave (*Key*).
La combinación de un *bucket* + *key* + *version ID* (opcional) identifica únicamente a cada uno de los objetos almacenados en S3. Analizaremos las *keys* más adelante.

### Regions
Es la región geográfica donde Amazon S3 almacenara el *bucket* que se está creando.
Elegir una región permite minimizar los costos, optimizar la latencia, o cumplir con requisitos legales o regulatorios. Amazon S3 permite replicar objetos entre regiones, lo veremos más adelante.

---
## Primeros pasos ##
Eso es todo lo que debemos saber (por ahora) para comenzar a utilizar las funciones básicas de S3.

Amazon S3 se accede desde la Consola de Administración de Amazon Web Services.
Una vez que se ingresa a la consola, en la barra de búsqueda escribir "S3" y seleccionar la consola de AWS S3.

![alt text](./images/S3_Console.png)

### Crear un *bucket*
* En el panel de S3, haga click en *Create Bucket*

![alt text](./images/S3_bucket_01.png)

* Introduzca el nombre del *bucket* y seleccione la región.
* Con esta información ya puede crear el *bucket* clickeando *Create*.
* O puede clickear *Next* para configurar Propiedades adicionales (control de versiones, etiquetas, logging) y/o Permisos. Dejemos todas esas opciones por defecto por ahora y complete la creación del *bucket*.
![alt text](./images/S3_bucket_02.png)


* Listo, ya puede ver la lista de sus *buckets*

![alt text](./images/S3_bucket_03.png)


### Subir objetos
* Seleccionar el *bucket* donde se quiere subir el objeto
![alt text](./images/S3_upload_01.png)

* Click en *Upload*
![alt text](./images/S3_upload_02.png)

* Seleccionar los archivos a subir (browse / drag&drop)
![alt text](./images/S3_upload_03.png)

* Clickear *Upload*.
* La barra de estado en la parte baja de la pantalla muestra el progreso. Una vez terminado, el objeto queda almacenado en el *bucket*.
![alt text](./images/S3_upload_04.png)

En forma opcional, al momento de realizar el upload se pueden configurar otras opciones sobre el objeto tales como:
* Permisos
* Permitir el acceso público al objeto
* Especificar la clase de storage donde se almacenará el objeto
* Opciones de cifrado
* Metadatos

Veremeos estas opciones mas adelante, por lo cual por ahora las dejaremos por defecto.


### Descargar objetos
* Seleccionar el objeto que se encuentra dentro del *bucket* (con el check-box a la izquierda del objeto).
* Se abre sobre la derecha el panel de propiedades.
* Click en *Download*
![alt text](./images/S3_download_01.png)

## Acceder a un objeto (acceso público)
Podemos darle permisos a nustros objetos para que los mismos puedan acceders en forma pública, por ej. desde un navegador web. Esto puede resultar útil a la hora de compartir información con otras personas que no tengan cuentas es AWS.
Para esto debemos habilitar los permisos necesiarios, que por defecto están deshabilitados.

Como vimos anteriormente, todo objeto que tenemos en un *bucket* es accesible mediante una *key*.
* Seleccionar el objeto dentro del *bucket* (con el chek-box).
* En el panel de propiedades copiar el *Link* y abrirlo en un browswer.
![alt text](./images/S3_public_01.png)

* El navegador nos da error y no podemos acceder al objeto. Esto es porque el objeto por defecto no tiene el acceso público habilitado.
![alt text](./images/S3_public_02.png)

* Para dar permiso de acceso público hay varias formas, la mas simple es:
   * seleccionar el objeto (ahora dando click en el nombre, no en el check-box).
   * luego: *Overview* >> *Make public*, y esperar que el proceso termine.
   ![alt text](./images/S3_public_03.png)
   * listo, ahora podemos volver a ingresar al link que habíamos copiado antes en el navegador y el objeto será accedido.
      

* El acceso público también se puede dar al momento de subir el objeto al *bucket*, o mediante permisos específicos sobre el objeto.
---
## Línea de Comandos de Amazon S3 ##

Ahora realizaremos operaciones báscas desde la línea de comando de Amazon S3 (CLI).

Requisito: se debe contar con un usuario creado en el AWS IAM, para poder contar con las credenciales necesarias para acceder a S3 desde línea de comando (*Access Key ID* y *Secret Access Key*)

### Descargar e instalar la línea de comandos
Es necesario descargar la línea de comandos desde la página de Amazon AWS (disponible para Windows, Linux y Mac).

Link: [Interfaz de línea de comando de AWS](https://aws.amazon.com/es/cli/)

Tanto desde Linux como Windows, si ya se tiene Python instalado, se puede instalar la AWS CLI mediante el comando pip (recomiendo hacerlo de este modo):
```bash
$ python --version
Python 3.6.1

$ pip install awscli
Collecting awscli
  Using cached awscli-1.11.130-py2.py3-none-any.whl
(...)
Installing collected packages: awscli
Successfully installed awscli-1.11.130

$ aws --version
aws-cli/1.11.130 Python/3.6.1 Windows/7 botocore/1.5.93
```


### Configuración inicial
Abra una consola (terminal en Linux o cmd en Windows), y luego:

```bash
$ aws configure
AWS Access Key ID [None]: AKIAWOINCOKAO3UZB4TN
AWS Secret Access Key [None]: 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
Default region name [None]: us-east-1
Default output format [None]: json
```

Donde:
- *AWS Access Key ID [None]:* clave de acceso de su usuario (generada por IAM)
- *AWS Secret Access Key [None]:* clave secreta de su usuario (generada por IAM)
- *Default region name [None]:* el nombre de la región, ej: us-east-1
- *Default output format [None]:* introduzca json

(las claves incluidas más arriba son ejemplos y no son válidas para el acceso)

### Utilizar la CLI

**Trabajando con *buckets***
Primero podemos listar la lista de *buckets* que tenemos actualmente:
```bash
$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
```
En este caso ya tenemos creado el *iot-cloud-bucket-1* que habíamos creado con la consola web.
Vamos a crear el *iot-cloud-bucket-2* mediante el comando *mb (make_bucket)*

```bash
$ aws s3 mb s3://iot-cloud-bucket-2
make_bucket: iot-cloud-bucket-2

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
2017-08-09 14:39:00 iot-cloud-bucket-2
```

Y podemos eliminar un *bucket* mediante *rb (remove_bucket)*
```bash
$ aws s3 rb s3://iot-cloud-bucket-2
remove_bucket: iot-cloud-bucket-2

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
```

**Trabajando con *objetos***

Para cargar el archivo *logo.png* del directorio local de nuestra máquina a un nuevo *bucket*, utilizamos el comando *cp*.

```bash
$ aws s3 mb s3://iot-cloud-bucket-nuevo
make_bucket: iot-cloud-bucket-nuevo

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
2017-08-09 15:01:18 iot-cloud-bucket-nuevo

$ aws s3 cp logo.png s3://iot-cloud-bucket-nuevo
upload: .\logo.png to s3://iot-cloud-bucket-nuevo/logo.png

$ aws s3 ls s3://iot-cloud-bucket-nuevo
2017-08-09 15:02:04       1753 logo.png
```

Para descargar el objeto *logo.png* desde S3 a nuestro disco local, utilizamos también el comando *cp* simplemente alternando origen/destino. En este caso lo bajamos a nuestra máquna local con otro nombre *logo-2.png* para no sobreescribir el existente (opcional):
```bash
$ aws s3 cp s3://iot-cloud-bucket-nuevo/logo.png ./logo-2.png
download: s3://iot-cloud-bucket-nuevo/logo.png to .\logo-2.png

$ ls
logo.png  logo-2.png
```

Para eliminar un objeto del *bucket* utilizamos el comando *rm* :
```bash
aws s3 rm s3://iot-cloud-bucket-nuevo/logo.png
delete: s3://iot-cloud-bucket-nuevo/logo.png
```

Refs:
[Almacenamiento de varios archivos en Amazon S3 con la CLI de AWS](https://aws.amazon.com/es/getting-started/tutorials/backup-to-s3-cli/)
[AWS CLI Command References: S3](http://docs.aws.amazon.com/cli/latest/reference/s3/)

---

[Siguiente >](.\20170810_AWS_S3_Parte_2.md)
