Amazon Simple Storage Service (Amazon S3)
===

*Fuentes:*
- [Documentación oficial](https://aws.amazon.com/es/documentation/s3/)
- [Página de AWS S3](https://aws.amazon.com/es/s3/)
- [Precios de AWS S3](http://aws.amazon.com/s3/pricing/)
- [AWS S3 Master Class](https://www.youtube.com/watch?v=VC0k-noNwOU)


## Indice.
---
- [Introducción](#introduccion)
- [Conceptos Básicos](#conceptos-básicos)


---
## Introducción ##
---
¿Qué es Amazon S3?      
---
Amazon S3 es un **almacenamiento de objetos** creado para almacenar y recuperar cualquier cantidad de datos desde cualquier ubicación: sitios web y aplicaciones móviles, aplicaciones corporativas y datos de sensores o dispositivos IoT.

Permite recopilar, almacenar y analizar datos de forma cómoda y sencilla, independientemente de su formato y a escala masiva. Es durable, seguro, y altamente escalable. Puede ser accedido desde la interface web, desde la línea de comando (Amazon CLI) y/o desde APIs. Puede utilizarse en forma aislada como un repositorio de datos, o en forma integrada con otros servicios de AWS.

### Características
* Fácil de usar
* Bajo costo
* Disponible (cuatro 9s)
* Durable (once 9s)
* Seguro
* Escalable
* Integrado con otros servicios AWS

### Casos de uso
* Backup & Archive
* Almacenar y distribuir contenido (fotos, videos, etc.)
* Static Website Hosting
* Big Data & Analytics
* Almacenamiento de nube híbrida
* Datos de aplicaciones Cloud-native
* Distaster recovery

Para soportar estos tipos de uso, Amazon S3 ofrece diferentes tipos de storages (*Storage Classes*), designados para diferentes modalidades de uso: *General purpose*, *Infrequent access*, y *Archive*.

Para ayudar a gestionar los datos, cuenta con un gestor de políticas (*Lifecycle Policies*) que permite mover los datos en forma automática entre las diferentes clases de storage.

También provee seguridad, control de acceso, y encriptación.

### Object Storage vs Traditional Storage

Existen varias diferencias entre las soluciones de almacenamiento tradicional (Block Storage, File Sotage) y las soluciones de almacenamiento de objetos (Object Storage).

En el siguiente artículo se puede encontrar información adicional:

   * [Introduction To Object Storage](https://blog.rackspace.com/introduction-to-object-storage)

---
## Conceptos Básicos ##
---

### Buckets
Son los depósitos donde se almacenan los objetos en S3. Representan el nivel mas alto de jerarquía dentro del almacenamiento. Cada objeto encuentra dentro de un *bucket*.
Se pueden crear y utilizar hasta 100 *buckets* por cada cuenta por defecto, y cada *bucket* puede contener miles de objetos.
s
El nombre del *bucket* debe ser único dentro de todos los existentes en Amazon S3 (no solo dentro de mi cuenta). Debe cumplir con una serie de reglas, debe tener entre 3 y 63 caracteres, no puede tener mayúsculas, ni espacios, ni caracteres especiales salvo guiones y puntos, entre otros.  

El nombre del *bucket* será visible en la URL que remite a los objetos almacenados en él. Una vez creado, el nombre no puede ser modificado.

Referencias:

[Working with Amazon S3 Buckets](http://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/UsingBucket.html)

[Restricciones y limitaciones en los Buckets](
http://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/BucketRestrictions.html)



### Objects
Son los objetos (archivos) almacenados en Amazon S3.
Un objeto puede contener cualquier tipo de datos en cualquier formato.
El tamaño máximo para un objeto es de 5TB, y un *bucket* puede contener una cantidad ilimitada de objetos.

Cada objeto consiste de *datos* (el archivo propiamente dicho) y *metadatos* (una serie de información acerca del archivo). La porción de *datos* es opaca a S3, es decir, es tratada como un simple conjunto de bytes sin importar su contenido. Los *metadatos* son pares de valores nombrados, que describen el objeto.

### Keys
Un objeto es identificado en forma única dentro de un *bucket* por una clave (*Key*).
La combinación de un *bucket* + *key* + *version ID* (opcional) identifica únicamente a cada uno de los objetos almacenados en S3.


### Regions
Es la región geográfica donde Amazon S3 almacenara el *bucket* que se está creando.
Elegir una región permite minimizar los costos, optimizar la latencia, o cumplir con requisitos legales o regulatorios.



---
## Primeros pasos ##

Eso es todo lo que debemos saber (por ahora) para comenzar a utilizar las funciones básicas de S3.

Amazon S3 se accede desde la Consola de Administración de Amazon Web Services.
Una vez que se ingresa a la consola, en la barra de búsqueda escribir "S3" y seleccionar la consola de AWS S3.


### Crear un *bucket*
* En el panel de S3, haga click en *Create Bucket*
* Introduzca el nombre del *bucket* y seleccione la región.
* Con esta información ya puede crear el *bucket* clickeando *Create*.
* O puede clickear *Next* para configurar Propiedades adicionales (control de versiones, etiquetas, logging) y/o Permisos. Dejemos todas esas opciones por defecto por ahora y complete la creación del *bucket*.
* Listo, ya puede ver la lista de sus *buckets*

### Subir objetos
* Seleccionar el *bucket* donde se quiere subir el objeto
* Seleccionar los archivos a subir (browse / drag&drop)
* Especificar permisos (dueño, acceso público)
* Especificar propiedades (clase de almacenamiento, cifrado y metadatos con su objeto)
* Clickear *Upload*
* Listo, el objeto queda almacenado en el *bucket*


### Descargar objetos
* Seleccionar el objeto (con el check-box a la izquierda del objeto)
* Se abre sobre la derecha el panel de propiedades
* Click en *download*


### Acceder a un objeto (acceso público)
* Seleccionar el objeto dentro del *bucket* (con el chek-box)
* En el panel de propiedades copiar el *Link* y abrirlo en un browswer
* Nos devuelve un error, porque el objeto por defecto no tiene acceso público
* Para dar permiso de acceso público hay varias formas, la mas simple es:
   * seleccionar el objeto (dando click en el nombre, no en el check-box)
   * luego: *Overview* >> *Make public*
   * listo, ahora podemos volver a ingresar al link que habíamos copiado antes y el objeto puede ser accedido públicamente desde el navegador
* El acceso público también se puede dar al momento de subir el objeto, o mediante los permisos del objeto.


Ref.: [Almacenamiento y recuperación de un archivo con Amazon S3 (tutorial)](
https://aws.amazon.com/es/getting-started/tutorials/backup-files-to-amazon-s3/)


**Static Web - Manage public permissions**

**Storage Clases**
* Standard
* Standard-IA
* Reduced redundancy

**Encryption**
* None
* Amazon S3 Master Key
* AWS KMS master-key


**Metadata**
* Header / Value




---
## Línea de comandos de Amazon S3 (CLI) ##

Ahora repitamos esto mismo, pero desde la línea de comando de Amazon S3 (CLI).

Requisito: se debe contar con un usuario creado en el AWS IAM, para poder contar con las credenciales necesarias para acceder a S3 desde línea de comando. Estos es la clave de acceso (*Access Key ID*) y la clave secreta del usuario (*Secret Access Key*)

### Descargar e instalar la línea de comandos
Es necesario descargar la línea de comandos desde la página de Amazon AWS.
Está disponible para Windows, Mac y Linux.
Siga el procedimiento de instalación dependiendo del sistema operativo.

Link: [Interfaz de línea de comando de AWS](https://aws.amazon.com/es/cli/)

En el caso de Windows, si ya se tiene Python instalado, recomiendo instalar la AWS CLI mediante el comando pip (esto evita recibir un mensaje de error luego de ciertos comandos):
```bash
$ python --version
Python 3.6.1

$ pip install awscli
Collecting awscli
  Using cached awscli-1.11.130-py2.py3-none-any.whl
(...)
Installing collected packages: awscli
Successfully installed awscli-1.11.130

$ aws --version
aws-cli/1.11.130 Python/3.6.1 Windows/7 botocore/1.5.93
```

### Configuración inicial
Abra una consola (terminal linux o cmd en Windows), y luego:

```bash
$ aws configure
AWS Access Key ID [None]: AKIAWOINCOKAO3UZB4TN
AWS Secret Access Key [None]: 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
Default region name [None]: us-east-1
Default output format [None]: json
```

Donde:
- *AWS Access Key ID [None]:* clave de acceso de su usuario (generada por IAM)
- *AWS Secret Access Key [None]:* clave secreta de su usuario (generada por IAM)
- *Default region name [None]:* el nombre de la región, ej: us-east-1
- *Default output format [None]:* introduzca json

(las claves incluidas más arriba son ejemplos y no son válidas para el acceso)

### Utilizar la CLI

**Trabajando con *buckets:***
Primero podemos listar la lista de *buckets* que tenemos actualmente:
```bash
$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
```
En este caso ya tenemos creado el *iot-cloud-bucket-1* que habíamos creado con la consola web.
Vamos a crear el *iot-cloud-bucket-2* mediante el comando *mb (make_bucket)*

```bash
$ aws s3 mb s3://iot-cloud-bucket-2
make_bucket: iot-cloud-bucket-2

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
2017-08-09 14:39:00 iot-cloud-bucket-2
```

Y podemos eliminar un *bucket* mediante *rb (remove_bucket)*
```bash
$ aws s3 rb s3://iot-cloud-bucket-2
remove_bucket: iot-cloud-bucket-2

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
```

**Trabajando con *objetos:***

Para cargar el archivo *logo.png* del directorio local de nuestra máquina a un nuevo *bucket*, utilizamos el comando *cp*:

```bash
$ aws s3 mb s3://iot-cloud-bucket-nuevo
make_bucket: iot-cloud-bucket-nuevo

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
2017-08-09 15:01:18 iot-cloud-bucket-nuevo

$ aws s3 cp logo.png s3://iot-cloud-bucket-nuevo
upload: .\logo.png to s3://iot-cloud-bucket-nuevo/logo.png

$ aws s3 ls s3://iot-cloud-bucket-nuevo
2017-08-09 15:02:04       1753 logo.png
```

Para descargar el objeto *logo.png* desde S3 a nuestro disco local, renombrandolo a *logo-2.png*:
```bash
$ aws s3 cp s3://iot-cloud-bucket-nuevo/logo.png ./logo-2.png
download: s3://iot-cloud-bucket-nuevo/logo.png to .\logo-2.png

$ ls
logo.png  logo-2.png
```

Para eliminar el objeto *logo.png* del bucket:
```bash
aws s3 rm s3://iot-cloud-bucket-nuevo/logo.png
delete: s3://iot-cloud-bucket-nuevo/logo.png
```

### Acceder a un objeto (acceso público)

Refs:
[Almacenamiento de varios archivos en Amazon S3 con la CLI de AWS (tutorial)](https://aws.amazon.com/es/getting-started/tutorials/backup-to-s3-cli/)
[AWS CLI Command References: S3](http://docs.aws.amazon.com/cli/latest/reference/s3/)
