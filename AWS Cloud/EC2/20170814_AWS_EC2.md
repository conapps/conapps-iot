Amazon Simple Storage Service (Amazon S3)
===

*Fuentes:*
- [Documentación oficial](https://aws.amazon.com/es/documentation/s3/)
- [Página de AWS S3](https://aws.amazon.com/es/s3/)
- [Precios de AWS S3](http://aws.amazon.com/s3/pricing/)
- [AWS S3 Master Class](https://www.youtube.com/watch?v=VC0k-noNwOU)


## Indice.
---
- [Introducción](#introduccion)
- [Conceptos Básicos](#conceptos-básicos)
- [Primeros Pasos](#primeros-pasos)
- [Linea de Comandos de Amazon S3](#línea-de-comandos-de-amazon-s3)
- [Folders](#folders)

---
## Introducción ##
---
¿Qué es Amazon EC2?      
---
EC2 es el servicio de computación más común que AWS ofrece, ya que permite implementar servidores virtuales dentro de su entorno AWS.
Y la mayoría de la gente requerirá un servidor en una forma u otra como parte de su solución. 

Reduce el tiempo necesario para obtener y arrancar nuevas instancias de servidor en cuestión de minutos, lo que permite escalar rápidamente la capacidad, ya sea aumentándola o reduciéndola, según cambien sus necesidades. 

Amazon EC2 cambia el modelo económico de la informática, ya que solo tendrá que pagar por la capacidad que realmente utilice. Amazon EC2 les brinda a los desarrolladores las herramientas necesarias para crear aplicaciones resistentes a errores y para aislarlas de los casos de error comunes.

***************

### Beneficios
* Informática a escala web elástica
* Totalmente controlado
* Servicios de hospedaje en la nube flexibles
* Integrado
* Fiabilidad
* Seguridad
* Fácil de comenzar

### Caso práctico de AWS: Netflix
AWS permite a Netflix desplegar rápidamente miles de servidores y terabytes de almacenamiento en cuestión de minutos. Los usuarios pueden ver programas y películas de Netflix desde cualquier parte del mundo, incluso en la web, en tabletas o en dispositivos móviles como el iPhone.

<div style="position:relative;height:0;padding-bottom:56.21%"><iframe src="https://www.youtube.com/embed/lQGHsBOZJBw?ecver=2" style="position:absolute;width:100%;height:100%;left:0" width="641" height="360" frameborder="0" allowfullscreen></iframe></div>


### El servicio EC2 puede dividirse en las siguientes secciones:
*	Amazon Machine Imágenes (AMIs)
*	Tipos de instancia
*	Opciones de compra de la instancia
*	Tenencia
*	datos del usuario
*	Opciones de almacenamiento
*	seguridad


### AMIs

Son esencialmente plantillas de instancias EC2 preconfiguradas que permiten iniciar rápidamente una nueva instancia EC2 basada en la configuración dentro del AMI. 

Esto evita tener que instalar un sistema operativo o cualquier otra aplicación común que pueda necesitar instalar en varias otras instancias de EC2. 

Desde una perspectiva de alto nivel, un AMI incluirá un sistema operativo y aplicaciones, junto con cualquier configuración personalizada.
AWS proporciona un gran número de AMIs que cubren diferentes sistemas operativos, desde Linux a Red Hat a Microsoft Windows, entre otros. 
Al configurar su instancia de EC2, seleccionar su AMI es la primera opción de configuración que debe realizar. También puede crear sus propias imágenes AMI para ayudarle a acelerar sus propias implementaciones.

Por ejemplo, empezaría con la selección de un AMI de AWS, digamos un servidor Linux. Una vez que esté funcionando, puede que necesite instalar varias de sus propias aplicaciones personalizadas y realizar cambios de configuración específicos. Ahora, si necesita otro servidor para realizar la misma funcionalidad, puede pasar por el mismo proceso de selección de un AMI de Linux AWS y, de nuevo, instalar manualmente sus aplicaciones y realizar sus configuraciones. 

Una vez que haya realizado esos cambios en el primer servidor, simplemente basta con crear un nuevo AMI de esa instancia con todas las aplicaciones instaladas y configuraciones ya realizadas. 
Entonces, si se necesita otro servidor de la misma configuración, todo lo que necesitará hacer es seleccionar su AMI personalizado como la imagen base de su instancia y lanzará el servidor Linux, sus aplicaciones personalizadas ya instaladas y cualquier configuración ya realizada.

Además de AWS-manejado y de su propio AMIs personalizado, también será posible seleccionar un AMI del mercado de AWS. El mercado de AWS es básicamente una tienda en línea que permite comprar AMIs de proveedores de confianza como Cisco, Citrix, Alert Logic, etc. 
Estos AMI de proveedores pueden tener aplicaciones y configuraciones específicas ya hechas, como las instancias optimizadas con seguridad incorporada Y herramientas de monitoreo o contengan sistemas de migración de bases de datos. Por último, también existen AMI de la comunidad, que son un repositorio de AMIs que han sido creados y compartidos por otros miembros de AWS.


**************************************************

### Tipos de Instancia
```bash
Un tipo de instancia simplemente define el tamaño de la instancia desde una CPU, memoria, almacenamiento y perspectiva de red. Tener esta flexibilidad de instancias variadas le permite seleccionar el tamaño o la potencia más apropiada de un servidor virtual que necesita para un rendimiento óptimo con sus aplicaciones.
```

Amazon EC2 permite elegir entre ***instancias de desempeño fijas*** (por ejemplo, M3, C3 y R3) e ***instancias de desempeño con ráfagas*** (por ejemplo, T2).

##Familias de Instancias

![alt text](./images/EC2_Available_Instance_Types.PNG)


**Instancias de Desempeño con Ráfagas**


Aquí es donde se encuentran las de propósito General.


Las instancias de desempeño con ráfagas, proporcionan un nivel base de desempeño de la CPU con la posibilidad de alcanzar ráfagas por encima del nivel básico. 

Uno de los tipos de instancias de desempeño con ráfagas son las T2 en las cuales el desempeño de referencia y la capacidad de alcanzar ráfagas se rigen por los créditos de la CPU.

 Cada instancia T2 recibe créditos de CPU continuamente a un nivel establecido dependiendo del tamaño de la instancia.  Las instancias T2 acumulan créditos de la CPU cuando están inactivas y los utilizan cuando están activas.  Las instancias T2 son una buena opción para cargas de trabajo que no usan la CPU por completo, a menudo o de manera constante, pero que de vez en cuando tienen que alcanzar ráfagas (por ejemplo, servidores web, entornos para desarrolladores y bases de datos). 

 Ilustraremos con un ejemplo mediante la siguiente tabla:

![alt text](./images/EC2_burst_Instance.png)

---
***Que son los créditos por hora de CPU?***

Son los encargados de aumentar el rendimiento de CPU de una instancia t2 en caso de necesidad puntual, las instancias t2 también llamadas de performance burstable o de ráfaga disponen de un rendimiento definido fijo como el que podemos ver en la tabla y de una capacidad  temporal extra limitada por los créditos por hora de CPU definidos.

La instancia arranca con un balance de créditos de CPU suficiente para que el performance sea bueno, mientras la instancia este en modo idle (o sin llegar a usar su baseline performance) los CPU Credits se acumulan según la tabla anterior CPU Credits / Hour, hasta llegar a 24 horas, donde si no se han gastado no se seguirán acumulando.

En el caso que una instancia requiera de un nivel de CPU superior a su Baseline Performance en momentos puntuales (ráfagas) usará los créditos disponibles acumulados hasta terminarlos y seguirá con el rendimiento marcado en su baseline performance.


*Ejemplos:*

*Supongamos que tenemos una instancia t2.micro encendida usando un 10% de CPU continuo (Su máximo permitido), en este caso se van acumulando a razón de 6 Créditos de CPU cada hora. 
Transcurridas 2 horas dispondremos de 12 minutos completos (2 horas x 6 créditos) en los que podremos usar el 100% de performance de un core de CPU a máximo rendimiento, transcurridos estos 12 minutos el sistema bajará su performance hasta un 10% de la potencia del core de CPU que es el asignado en su baseline.*



*Notas:* 

* *El sistema operativo seguirá indicando que está al 100% de CPU si el proceso no ha finalizado, pero irá un 90% más lento que en los 12 minutos anteriores donde pudimos disfrutar de la máxima potencia del core físico asignado a la máquina virtual.*

* *En el caso de una instancia t2.large dispondremos siempre de un 60% del core de CPU para nuestro uso y disfrute, en el caso puntual que necesitemos superar este rendimiento, el sistema cogerá de su reserva de CPU Crédits lo acumulado a razón de 36 créditos por hora el establecido en la primera imagen del artículo.*
*Si el uso de CPU de la instancia t2.large fuera inferior a un 60% de CPU durante 24 horas, dispondríamos de 14 horas o 864 minutos de uso del sistema al 100% de su capacidad de procesamiento (24 horas *36 créditos), transcurrido este tiempo volveríamos a disponer de un 60% de rendimiento del core.*

* *En el caso de las instancias t2 medium y large que disponen de 2 vCPU significa que tienen el doble de capacidad de proceso? Pues no. En el caso de t2 medium tiene como base un 40% de un núcleo disponible para un único proceso (1 vCPU) pero si utiliza multiproceso (2 vCPU) dispondrá de un 20% por cada proceso. en el caso de t2.large lo mismo pero con un 60% de una vCPU y de un 30% si es multiproceso.*


---

**Formato de Desempeño de las Instancias**

Cuando inicia una instancia, el tipo de instancia que especifique determina el hardware del equipo host utilizado para su instancia. Cada tipo de instancia ofrece diferentes capacidades de cálculo, memoria y almacenamiento y se agrupan en familias de instancias basadas en estas capacidades. Seleccione un tipo de instancia basado en los requisitos de la aplicación o el software que planea ejecutar en su instancia.

Amazon EC2 proporciona a cada instancia una cantidad consistente y previsible de capacidad de CPU, independientemente de su hardware subyacente.

Amazon EC2 dedica algunos recursos del equipo host, como CPU, memoria y almacenamiento de instancias, a una instancia particular. Amazon EC2 comparte otros recursos de la computadora host, como la red y el subsistema de disco, entre instancias. Si cada instancia de un equipo host intenta utilizar tanto de uno de estos recursos compartidos como sea posible, cada uno recibe un porcentaje igual de ese recurso. Sin embargo, cuando un recurso está infrautilizado, una instancia puede consumir una mayor proporción de ese recurso mientras esté disponible.

Cada tipo de instancia proporciona un rendimiento mínimo superior o inferior de un recurso compartido. Por ejemplo, los tipos de instancia con alto rendimiento de E / S tienen una mayor asignación de recursos compartidos. La asignación de una mayor proporción de recursos compartidos también reduce la varianza del rendimiento de E / S. Para la mayoría de las aplicaciones, un rendimiento de E / S moderado es más que suficiente. Sin embargo, para aplicaciones que requieren un rendimiento de E / S mayor o más consistente, considere un tipo de instancia con mayor rendimiento de E / S.



**Instancias de Desempeño fijo**

Garantizan entregar los recursos en forma constante.
Pensada para satisfacer aquellos requerimientos, donde es importante un desempeño de la CPU alto de manera consistente para aplicaciones como, por ejemplo,codificación de video, sitios web de alto volumen o aplicaciones HPC (High Performance Computing)


<u>**Algunos tipos de instancias de Desempeño Fijo:**</u>

  Optimizadas para Cómputo

  Memoria optimizada

  Almacenamiento optimizado

  Computación Acelerada

* **Almacenamiento Optimizado**

  Las instancias optimizadas de almacenamiento están diseñadas para cargas de trabajo que requieren un alto acceso secuencial de lectura y escritura a conjuntos de datos muy grandes en el almacenamiento local. Están optimizadas para entregar decenas de miles de operaciones de E / S aleatorias de baja latencia por segundo (IOPS) a aplicaciones.


* **Memoria optimizada (Instancias X1):**

  **Descripción:**

    Los tipos de instancia aquí se utilizan principalmente para aplicaciones de gran escala, de clase empresarial, en memoria, tales como realizar el procesamiento en tiempo real de datos no estructurados o para bases de datos en memoria como SAP HANA. 
    
    Las instancias de esta familia utilizan almacenamiento de instancia con respaldo SSD para baja latencia y un rendimiento de entrada / salida muy alto, incluyendo IOPS muy alto, que significa operaciones de salida de entrada por segundo. 
  
    Estos son ideales para cargas de trabajo analíticas y no bases de datos SQL, sistemas de archivos de datos y aplicaciones de procesamiento de bloqueo. Puede comprar instancias de EC2 a través de una variedad de diferentes planes de pago. Estos han sido diseñados para ayudarle a ahorrar costes seleccionando la opción más apropiada para su despliegue. 
  
    Las instancias X1 están optimizadas para aplicaciones en la memoria a larga escala de clase empresarial y ofrecen el costo más bajo por GiB de RAM entre los tipos de instancias de Amazon EC2.

  
  **Características:**

  * Procesadores Intel Xeon E7-8880 v3 (Haswell) de alta frecuencia
  * Precio más bajo por GiB de RAM
  * Hasta 1 952 GiB de memoria de instancia basada en DDR4
  * Almacenamiento SSD y optimizadas para EBS por defecto sin costo adicional
  * Posibilidad de controlar la configuración del estado C y P del procesador

  **Casos de uso**

  Se recomiendan las instancias X1 para ejecutar bases de datos en memoria como SAP HANA, motores de procesamiento de big data como Apache Spark o Presto, y aplicaciones informáticas de alto desempeño (HPC). 
  
  Las instancias X1 están certificadas por SAP para la ejecución de Business Warehouse en HANA (BW), soluciones de centros de datos en HANA, Business Suite en HANA (SoH), y Business Suite S/4HANA de siguiente generación en un entorno de producción en la nube de AWS.



* **Computación Acelerada (P2)**

    **Descripción:**

    
  Si necesita una alta capacidad de procesamiento, se beneficiará del uso de instancias de computación acelerada, que proporcionan acceso a aceleradores de cálculo basados ​​en hardware como GPUs o Field Programmable Gate Arrays (FPGA). Las instancias de computación acelerada permiten mayor paralelismo para un mayor rendimiento en cargas de trabajo intensivas en computación.

  Las instancias basadas en GPU proporcionan acceso a las GPU NVIDIA con miles de núcleos de cálculo. Puede utilizar instancias de computación acelerada basadas en GPU para acelerar las aplicaciones científicas, de ingeniería y de procesamiento aprovechando los frameworks de computación paralelo CUDA o Open Computing Language (OpenCL). También puede utilizarlos para aplicaciones gráficas, como streaming de juegos, transmisión de aplicaciones 3D y otras cargas de trabajo de gráficos.


  **Características:**
  
  * Procesadores Intel Xeon E5-2686v4 (Broadwell) de alta frecuencia.
  * GPU NVIDIA K80 de alto desempeño, cada unidad con 2 496 núcleos de procesamiento paralelo y     12 GiB de memoria GPU
  *	Compatible con GPUDirect™ (comunicación GPU punto a punto)
  *	Proporciona redes mejoradas con el adaptador de red elástico de Amazon EC2, que ofrece hasta    20 Gbps de ancho de banda total en un grupo de ubicación.

  *	Optimizados para EBS de manera predeterminada sin costos adicionales





* **Optimizadas para Cómputo**
 
  **Descripción:**

  Esta familia incluye instancias de gran capacidad de almacenamiento que ofrecen almacenamiento de instancias respaldado por SSD en memoria no volátil exprés (NVMe) optimizado para baja latencia, desempeño de E/S aleatoria muy alta, desempeño de lectura secuencial alto y ofrecen IOPS altas a bajo costo.


---
### Formas de Adquisición:

* Reservadas
  
  Las instancias reservadas (IR) de Amazon EC2 proporcionan un descuento importante (de hasta el 75%) en comparación con el precio de las instancias bajo demanda y brindan una reserva de capacidad cuando se utilizan en una zona de disponibilidad específica.

  Por otra parte el mercado de instancias reservadas permite a otros clientes de AWS publicar sus IR estándares para la venta. Las IR estándares de terceros no presentan diferencias con las instancias reservadas estándares que se adquieren directamente a AWS, con la excepción de que ofrecen precios menores y plazos más cortos.


  Tipos:

  * IR estándares: 
      
      Ofrecen el mayor descuento (hasta un 75% en comparación con las instancias bajo demanda) y están mejor preparadas para el uso de estado constante.
      
      Plazos: AWS ofrece IR estándares en plazos de 1 o 3 años.
  
  * IR convertibles: 
  
      Ofrecen un descuento (hasta un 54% en comparación con las instancias bajo demanda) y la capacidad para cambiar los atributos de la IR siempre y cuando el intercambio resulte en la creación de instancias reservadas de un valor equivalente o superior. Al igual que las IR estándares, las IR convertibles están mejor preparadas para el uso de estado constante.
      
      AWS ofrece IR convertibles en plazos de 3 años.
     

  * IR programadas: 
      
      Se pueden lanzar en los intervalos de tiempo para los que se hayan reservado. Esta opción permite adecuar la reserva de capacidad a un cronograma recurrente y previsible que solo ocupe una fracción de un día, una semana o un mes.





* On Demand
  
  Con las instancias bajo demanda, solo paga por las instancias de EC2 que utiliza. El uso de las instancias bajo demanda elimina los costos y las complejidades de la planificación, la compra y el mantenimiento del hardware y se transforma lo que normalmente son grandes costos fijos en costos variables mucho más reducidos. 

  Características:
  
  * Las instancias bajo demanda permiten pagar por la capacidad de cómputo por horas sin       
    compromisos a largo plazo. Así se eliminan los costos y las complejidades de la planificación,la compra y el mantenimiento del hardware y se transforma lo que normalmente son grandes costos fijos en costos variables mucho más reducidos.

  * Los precios se calculan por hora de instancia consumida para cada instancia, desde el momento   en el que se lanza hasta que se finaliza o detiene. Cada porción de hora de instancia           consumida se facturará como hora completa.



* Spot.
  
  Permiten pujar por la capacidad informática de Amazon EC2 que quede libre. 
  A menudo se ofrecen descuentos para las instancias de subasta. 
  Esto supone que, por el mismo presupuesto que el invertido en los precios bajo demanda, puede reducir considerablemente el costo de ejecutar las aplicaciones, aumentar la capacidad de cómputo y de desempeño de las aplicaciones, y habilitar nuevos tipos de aplicaciones de informática en la nube.

  Beneficios

  * Las instancias de subasta se ejecutan cuando su precio de puja supera el precio de subasta y    ponen a su alcance la fiabilidad, la seguridad, el desempeño, el control y la elasticidad de Amazon EC2 a precios reducidos acordes al mercado.

  * Reducción de los costos operacionales.

    Es posible reducir los costos operacionales hasta en un 50-90% con las instancias de subasta, en comparación con las instancias bajo demanda.
    El precio de subasta fluctúa en función de la oferta y la demanda de capacidad de EC2 disponible sin uso.
  
    Cuando solicita instancias de subasta, debe especificar el precio máximo de subasta que está dispuesto a pagar.  Su instancia de subasta se lanza cuando el precio de subasta es menor que el precio que especificó y continuará ejecutándose hasta que decida finalizarla o hasta que el precio de subasta exceda el precio máximo que especificó.

    Con las instancias de subasta, nunca se le cobra más que el precio máximo que especificó.  Mientras su instancia se encuentre en ejecución, se le cobrará el precio de subasta vigente durante dicho período. 

    Si el precio de subasta excede el precio que especificó, la instancia recibirá una notificación dos minutos antes de que se finalice, y no se le cobrará la hora parcial durante la cual la instancia se haya ejecutado.

    Si incluye un requisito de duración en la solicitud de instancia de subasta, la instancia continúa ejecutándose hasta que decida cerrarla o hasta que se cumpla la duración especificada; no se cerrará por cambios en el precio de subasta.




  * Mejora en el desempeño de la aplicación
  
    En las instancias de subasta se pueden ejecutar y escalar aplicaciones, como por ejemplo, servicios web sin estado, representaciones de imágenes, análisis de big data y cómputos masivamente paralelos. Dado que las instancias de subasta suelen costar un 50-90% menos, esto le permite la capacidad de cómputo en 2-10x contando con el mismo presupuesto.



---

### Opciones de Tenencia



AKKKKKK


Para soportar estos tipos de uso, Amazon S3 ofrece diferentes tipos de storages (*Storage Classes*), designados para diferentes modalidades de uso: *General purpose*, *Infrequent access*, y *Archive*.

Para ayudar a gestionar los datos, cuenta con un gestor de políticas (*Lifecycle Policies*) que permite mover los datos en forma automática entre las diferentes clases de storage.

También provee seguridad, control de acceso, y encriptación.

### Object Storage vs Traditional Storage

Existen varias diferencias entre las soluciones de almacenamiento tradicional (Block Storage, File Sotage) y las soluciones de almacenamiento de objetos (Object Storage).

En el siguiente artículo se puede encontrar información adicional:

   * [Introduction To Object Storage](https://blog.rackspace.com/introduction-to-object-storage)

---
## Conceptos Básicos ##
---

### Buckets
Son los depósitos donde se almacenan los objetos en S3. Representan el nivel mas alto de jerarquía dentro del almacenamiento. Cada objeto encuentra dentro de un *bucket*.
Se pueden crear y utilizar hasta 100 *buckets* por cada cuenta por defecto, y cada *bucket* puede contener miles de objetos.

El nombre del *bucket* debe ser único dentro de todos los existentes en Amazon S3 (no solo dentro de mi cuenta). Debe cumplir con una serie de reglas, debe tener entre 3 y 63 caracteres, no puede tener mayúsculas, ni espacios, ni caracteres especiales salvo guiones y puntos, entre otros.  

El nombre del *bucket* será visible en la URL que remite a los objetos almacenados en él. Una vez creado, el nombre no puede ser modificado.

Referencias:
    [Working with Amazon S3 Buckets](http://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/UsingBucket.html)
    [Restricciones y limitaciones en los Buckets](http://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/BucketRestrictions.html)


### Objects
Son los objetos (archivos) almacenados en Amazon S3.
Un objeto puede contener cualquier tipo de datos en cualquier formato.
El tamaño máximo para un objeto es de 5TB, y un *bucket* puede contener una cantidad ilimitada de objetos.

Cada objeto consiste de *datos* (el archivo propiamente dicho) y *metadatos* (una serie de información acerca del archivo). La porción de *datos* es opaca a S3, es decir, es tratada como un simple conjunto de bytes sin importar su contenido. Los *metadatos* son pares de valores nombrados, que describen el objeto.

### Keys
Cada objeto almacenado dentro de *bucket* es identificado en forma única por un clave (*Key*). Se podría pensar en la *key* como si fuera el *filename* del objeto.
La *key* puede contener hasta 1024 caracteres, incluyendo barra (/), retrobarra (\\), punto, y guión.

La clave debe ser única dentro de un *bucket*, pero diferentes *buckets* pueden contener objetos con la misma clave.
La combinación de *bucket* + *key* + *version ID* (opcional) identifica en forma única a un objeto almacenados en S3.

Ejemplo de clave: */datos/informes/2017/01/reporte-de-horas.doc*

### URL del objeto
Cada uno de los objetos almacenados en S3 puede ser accedido mediante una URL única, la cual se conforma del *Amazon web services endpoint*, el nombre del *bucket*, y la *key* del objeto.

La URL puede tener estos dos formatos:
http(s)://*\<bucket-name\>*.s3.amazonaws.com/*\<object-key\>*
http(s)://s3.amazonaws.com\/*\<bucket-name\>*/*\<object-key\>*

Esto puede cambiar sensiblemente, dado que el dominio de aws generalmente incluye también la region (ej. s3-us-west-2.amazonaws.com) y la *bucket-key* puede incluir una serie de carpetas dentro (*folders*).

Por ej.:
https://s3-us-west-2.amazonaws.com/my-bucket/document.doc
https://bucket-auditoria.s3-us-west-2.amazonaws.com/datos/informes/2017/01/reporte-de-horas.doc


### Regiones
Es la región geográfica donde Amazon S3 almacenara el *bucket* que se está creando.
Elegir una región permite minimizar los costos, optimizar la latencia, o cumplir con requisitos legales o regulatorios. Amazon S3 permite replicar objetos entre regiones, lo veremos más adelante.

---
## Primeros pasos ##
Eso es todo lo que debemos saber (por ahora) para comenzar a utilizar las funciones básicas de S3.

Amazon S3 se accede desde la Consola de Administración de Amazon Web Services.
Una vez que se ingresa a la consola, en la barra de búsqueda escribir "S3" y seleccionar la consola de AWS S3.

![alt text](./images/S3_Console.png)

### Crear un *bucket*
* En el panel de S3, haga click en *Create Bucket*

![alt text](./images/S3_bucket_01.png)

* Introduzca el nombre del *bucket* y seleccione la región.
* Con esta información ya puede crear el *bucket* clickeando *Create*.
* O puede clickear *Next* para configurar Propiedades adicionales (control de versiones, etiquetas, logging) y/o Permisos. Dejemos todas esas opciones por defecto por ahora y complete la creación del *bucket*.
![alt text](./images/S3_bucket_02.png)


* Listo, ya puede ver la lista de sus *buckets*

![alt text](./images/S3_bucket_03.png)


### Subir objetos
* Seleccionar el *bucket* donde se quiere subir el objeto
![alt text](./images/S3_upload_01.png)

* Click en *Upload*
![alt text](./images/S3_upload_02.png)

* Seleccionar los archivos a subir (browse / drag&drop)
![alt text](./images/S3_upload_03.png)

* Clickear *Upload*.
* La barra de estado en la parte baja de la pantalla muestra el progreso. Una vez terminado, el objeto queda almacenado en el *bucket*.
![alt text](./images/S3_upload_04.png)

En forma opcional, al momento de realizar el upload se pueden configurar otras opciones sobre el objeto tales como:
* Permisos
* Permitir el acceso público al objeto
* Especificar la clase de storage donde se almacenará el objeto
* Opciones de cifrado
* Metadatos

Veremos estas opciones mas adelante, por lo cual por ahora las dejaremos por defecto.


### Descargar objetos
* Seleccionar el objeto que se encuentra dentro del *bucket* (con el check-box a la izquierda del objeto).
* Se abre sobre la derecha el panel de propiedades.
* Click en *Download*
![alt text](./images/S3_download_01.png)

## Acceder a un objeto (acceso público)
Podemos darle permisos a nuestros objetos para que los mismos puedan accederlos en forma pública, por ej. desde un navegador web. Esto puede resultar útil a la hora de compartir información con otras personas que no tengan cuentas es AWS.
Para esto debemos habilitar los permisos necesarios, que por defecto están deshabilitados.

Como vimos anteriormente, todo objeto que tenemos en un *bucket* es accesible mediante una *key*.
* Seleccionar el objeto dentro del *bucket* (con el chek-box).
* En el panel de propiedades copiar el *Link* y abrirlo en un browser.
![alt text](./images/S3_public_01.png)

* El navegador nos da error y no podemos acceder al objeto. Esto es porque el objeto por defecto no tiene el acceso público habilitado.
![alt text](./images/S3_public_02.png)

* Para dar permiso de acceso público hay varias formas, la mas simple es:
   * seleccionar el objeto (ahora dando click en el nombre, no en el check-box).
   * luego: *Overview* >> *Make public*, y esperar que el proceso termine.
   ![alt text](./images/S3_public_03.png)
   * listo, ahora podemos volver a ingresar al link que habíamos copiado antes en el navegador y el objeto será accedido.

* El acceso público también se puede dar al momento de subir el objeto al *bucket*, o mediante permisos específicos sobre el objeto.
---
## Línea de Comandos de Amazon S3 ##

Ahora realizaremos operaciones básicas desde la línea de comando de Amazon S3 (CLI).

Requisito: se debe contar con un usuario creado en el AWS IAM, para poder contar con las credenciales necesarias para acceder a S3 desde línea de comando (*Access Key ID* y *Secret Access Key*)

### Descargar e instalar la línea de comandos
Es necesario descargar la línea de comandos desde la página de Amazon AWS (disponible para Windows, Linux y Mac).

Link: [Interfaz de línea de comando de AWS](https://aws.amazon.com/es/cli/)

Tanto desde Linux como Windows, si ya se tiene Python instalado, se puede instalar la AWS CLI mediante el comando pip:
```bash
$ python --version
Python 3.6.1

$ pip install awscli
Collecting awscli
  Using cached awscli-1.11.130-py2.py3-none-any.whl
(...)
Installing collected packages: awscli
Successfully installed awscli-1.11.130

$ aws --version
aws-cli/1.11.130 Python/3.6.1 Windows/7 botocore/1.5.93
```


### Configuración inicial
Abra una consola (terminal en Linux o cmd en Windows), y luego:

```bash
$ aws configure
AWS Access Key ID [None]: AKIAWOINCOKAO3UZB4TN
AWS Secret Access Key [None]: 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
Default region name [None]: us-east-1
Default output format [None]: json
```

Donde:
- *AWS Access Key ID [None]:* clave de acceso de su usuario (generada por IAM)
- *AWS Secret Access Key [None]:* clave secreta de su usuario (generada por IAM)
- *Default region name [None]:* el nombre de la región, ej: us-east-1
- *Default output format [None]:* introduzca json

(las claves incluidas más arriba son ejemplos y no son válidas para el acceso)

### Utilizando la AWS CLI

**Trabajando con *buckets***
Primero podemos listar la lista de *buckets* que tenemos actualmente:
```bash
$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
```
En este caso ya tenemos creado el *iot-cloud-bucket-1* que habíamos creado con la consola web.
Vamos a crear el *iot-cloud-bucket-2* mediante el comando *mb (make_bucket)*

```bash
$ aws s3 mb s3://iot-cloud-bucket-2
make_bucket: iot-cloud-bucket-2

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
2017-08-09 14:39:00 iot-cloud-bucket-2
```

Y podemos eliminar un *bucket* mediante *rb (remove_bucket)*
```bash
$ aws s3 rb s3://iot-cloud-bucket-2
remove_bucket: iot-cloud-bucket-2

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
```

**Trabajando con *objetos***
Para cargar el archivo *logo.png* del directorio local de nuestra máquina a un nuevo *bucket*, utilizamos el comando *cp*.

```bash
$ aws s3 mb s3://iot-cloud-bucket-nuevo
make_bucket: iot-cloud-bucket-nuevo

$ aws s3 ls
2017-08-08 16:33:33 iot-cloud-bucket-1
2017-08-09 15:01:18 iot-cloud-bucket-nuevo

$ aws s3 cp logo.png s3://iot-cloud-bucket-nuevo
upload: .\logo.png to s3://iot-cloud-bucket-nuevo/logo.png

$ aws s3 ls s3://iot-cloud-bucket-nuevo
2017-08-09 15:02:04       1753 logo.png
```

Para descargar el objeto *logo.png* desde S3 a nuestro disco local, utilizamos también el comando *cp* simplemente alternando origen/destino. En este caso lo bajamos a nuestra máquina local con otro nombre *logo-2.png* para no sobrescribir el existente (opcional):
```bash
$ aws s3 cp s3://iot-cloud-bucket-nuevo/logo.png ./logo-2.png
download: s3://iot-cloud-bucket-nuevo/logo.png to .\logo-2.png

$ ls
logo.png  logo-2.png
```

Para eliminar un objeto del *bucket* utilizamos el comando *rm* :
```bash
aws s3 rm s3://iot-cloud-bucket-nuevo/logo.png
delete: s3://iot-cloud-bucket-nuevo/logo.png
```

Refs:
[AWS CLI Command References S3](http://docs.aws.amazon.com/cli/latest/reference/s3/)

---
## Folders

Amazon S3 es una solución de *object storage*, y tiene por tanto una estructura plana, sin la jerarquía de directorios que podemos encontrar en un típico filesystem.
Los *buckets* y los *objects* son los recursos principales, donde los objetos se almacenan dentro de los buckets.
Pero, con el objetivo de poder organizar mejor los datos, Amazon S3 soporta el concepto de *folders*, en el entendido que las mismas agrupan los objetos (pero sin crear una jerarquía como tal). Esto se realiza utilizando ***prefixes*** (prefijos) en las *keys* de los objetos.

Por ejemplo, dentro de un *bucket* se puede crear una carpeta llamada "fotos", y almacenar un ella un objeto llamado "mifoto.jpg". El objeto es entonces almacenado con el *key name* "fotos/mifoto.jpg", donde "fotos/" es el prefijo del objeto.

El concepto de prefijo es importante, dado que luego podremos utilizar diferentes funcionalidades y/o servicios realizando operaciones sobre ciertos objetos que contengan determinado prefijo (espero que mas adelante esto se entienda mejor).

Se pueden crear carpetas dentro de carpetas, pero no *buckets* dentro de *buckets*. Se pueden subir o copiar objetos directo a una carpeta, y los objetos se pueden mover de una carpeta a otra. Las carpetas se pueden crear, borrar, y hacer públicas, pero no se pueden renombrar.

Desde la consola web podemos crear un folder fácilmente, cuando estamos dentro de un *bucket*:
![alt text](./images/S3_folders_01.png)

Y podemos subir objetos de la misma forma que lo hicimos antes.
![alt text](./images/S3_folders_02.png)

También podemos subir objetos a carpetas utilizando la CLI:
```bash
$ mkdir logs;
$ touch logs/file1 logs/file2 logs/file3

$ aws s3 cp . s3://iot-cloud-bucket-1/ --recursive
upload: logs\file3 to s3://iot-cloud-bucket-1/logs/file3
upload: logs\file2 to s3://iot-cloud-bucket-1/logs/file2
upload: logs\file1 to s3://iot-cloud-bucket-1/logs/file1
```

O sincronizar una carpeta local con todo su contenido:
```bash
$ touch file4 file5; mkdir otra_carpeta; touch otra_carpeta/file6

$ aws s3 sync . s3://iot-cloud-bucket-1
upload: .\file4 to s3://iot-cloud-bucket-1/file4
upload: otra_carpeta\file6 to s3://iot-cloud-bucket-1/otra_carpeta/file6
upload: .\file5 to s3://iot-cloud-bucket-1/file5
```
El comando *sync* solo actualiza los archivos actuales y sube los nuevos, pero no borra objetos salvo que le agreguemos *--delete*:
```bash
$ rm file5 logs/file1

$ aws s3 sync . s3://iot-cloud-bucket-1

$ aws s3 sync . s3://iot-cloud-bucket-1 --delete
delete: s3://iot-cloud-bucket-1/file5
delete: s3://iot-cloud-bucket-1/logs/file1
```

Refs:
[Working with Folders](http://docs.aws.amazon.com/es_es/AmazonS3/latest/UG/FolderOperations.html)
[AWS CLI Command References S3](http://docs.aws.amazon.com/cli/latest/reference/s3/)


---
[Siguiente >](https://github.com/conapps/conapps-iot/blob/master/AWS%20Cloud/S3/20170810_AWS_S3_Parte_2.md)
