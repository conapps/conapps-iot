<-- [Volver](https://github.com/conapps/conapps-iot/blob/master/claseDeDocker/20170801-Docker.md)

## Imágenes
---

Hasta ahora hemos creado contenedores provenientes de imagenes creadas por terceros. Ahora vamos a explorar los pasos necesarios para crear nuestras propias imágenes.

### Docker commit

Supongamos que generamos un container a partir de la última imagen de ubuntu de la siguiente manera:

```bash
$ docker run --name segunda-prueba -i -t ubuntu bash
root@1dbc76e3acdb:/#
```

Esto nos deja posicionados dentro de este nuevo contenedor, esto es gracias a las opciones ```-i``` que conecta la entrada estándar, en este caso el teclado, al contenedor generando una sesión interactiva y ```-t``` que asigna un terminal virtual al contenedor redirigiendo su salida estándar al monitor. Podemos ver que estamos dentro del contenedor y no dentro de nuestra máquina al observar el prompt, que como puede verse el en cuadro de texto mas arriba debería ser del estilo ```root@1dbc76e3acdb:/#```.

Supongamos ahora que queremos abrir un intérprete de Python:

```bash
root@1dbc76e3acdb:/# python
bash: python: command not found
```
El problema aquí es que Python no está instalado, a continuación lo instalamos:

```bash
root@e6387986f32b:/# apt-get update && apt-get install -y python
Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [102 kB]
Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]
Get:3 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [43.0 kB]
Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [406 kB]
Get:5 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [102 kB]         
Get:6 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.8 kB]
Get:7 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [187 kB]
Get:8 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [2931 B]
----> SALIDA OMITIDA PARA MAYOR CLARIDAD <---
```

Una vez finalizado el proceso de instalación ya podemos utilizar Python:

```bash
root@e6387986f32b:/# python
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>>
>>>
>>>
>>> exit()
root@e6387986f32b:/#
```

En este punto tenemos un contenedor completamente funcional que cumple con todas nuestras necesidades, en este caso únicamente Python'.
Pero que sucede si ahora queremos utilizar este contenedor en producción fuera de nuestra máquina local. Esto de hecho es una de las fortalezas mas importantes de la tecnología de contenedores, esto es, la posibilidad de crear un ambiente en nuestra máquina local y luego exportar y utilizar dicho ambiente en producción con exactamente los mismos paquetes y dependencias instaladas que lo que tenemos localmente (lo que utilizamos para desarrollar).
El problema aquí es que, a diferencia del transporte marítimo, en Docker lo que se transporta no son los contenedores sino las imágenes y a partir de una imágen se pueden generar cualquier cantidad de contenedores idénticos.
Dicho esto, si queremos transportar nuestro nuevo ambiente con Python instalado sobre una distribución Ubuntu, el desafío es generar una nueva imágen, dado que la imagen de la cual partimos no contiene Python. Para esto utilizaremos el comando ```docker commit <contenedor> <nombre-de-la-nueva-imagen>```, por ejemplo:

```$
$ docker commit segunda-prueba ambiente-produccion
sha256:c2a9520001342c424d141f05c6f13761a74d58edd336f11b7a971c1a1d2ed317
$ docker images
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
ambiente-produccion       latest              c2a952000134        5 seconds ago       189.2 MB
```

Ahora que tengo una nueva imagen desde la cual generar contenedores con mi ambiente, podría eliminar el contenedor y volver a regenerarlo. Como se puede ver en el cuadro a continuación el nuevo contenedor ya tiene Python instalado:

```bash
$ docker rm segunda-prueba
segunda-prueba

$ docker run --name tercera-prueba -it ambiente-produccion bash
root@0f66ed1e694d:/# python
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>>
>>> exit()
root@0f66ed1e694d:/#
root@0f66ed1e694d:/#
```

### Dockerfile

El método anterior sirve para generar imágenes a partir de contenedores, pero tiene muchas desventajas a la hora de su uso en producción.
Es poco flexible y la imagen no está optimizada para versionarse al igual que hacemos con nuestro código. Profundicemos sobre este punto con un ejemplo.
Supongamos que nuestro ambiente de producción no incluye únicamente Python, sino también python-pip, python-dev, libmysqlclient-dev, MySQL-python, requests, nginx, Django, MySQL, open-ssh, y tpftpd-hpa.
Pensemos en el proceso para armar un ambiente de este tipo; habría que generar un contenedor con Ubuntu, instalar todos estos paquetes y luego hacer un commit. Ahora, ¿qué pasaría si durante nuestro proceso de desarrollo decidimos explorar la posiblidad de cambiar nuestro motor de base de datos de MySQL a PostgreSQL? ¿Cómo haríamos para generar una nueva imágen? Podríamos intentar desinstalar MySQL e instalar PostgreSQL en su lugar, pero veamos que hay muchas dependencias como libmysqlclient-dev y MySQL-python que solo tienen sentido si utilizamos MySQL y que deberían también ser desinstaladas para mantener "limpia" nuestra imagen que luego será utilzada en producción. Finalmente habría que instalar los módulos de Python correspondientes para trabajar con una base de datos PostgreSQL y hacer un commit para generar la nueva imagen.

Principales desventajas del enfoque anterior:

  - Si la desición de cambiar a PostgreSQL se toma varias semanas o  meses luego de generada la primer imagen, probablemente no recuerde que existían las librerías de Python que Soportan MySQL dado que los paquetes que hay instalados en la imagen no quedan documentados en ningún sitio.
  - Los cambios en los ambientes de desarrollo pueden darse decenas de veces en el transcurso de un proyecto, la desinstalación de módulos y librerías que ya no son necesarias puede volverse una tarea tediosa.
  - En general cada cambio en el ambiente de desarrollo viene acompañado por un cambio en el código fuente de nuestra aplicación, lo que nos gustaría poder hacer es versionar nuestro ambiente utilizando los mismos mecanismos que utilizamos para versionar nuestro código. Pero cada nueva imagen generada con el método ```$ docker commit``` pesa cientos de Megas.
  - Si queremos reutilizar nuestro ambiente para otro desarrollo no tenemos visibilidad de qué software hay instalado en la imagen para poder adaptarlo a las necesidades del nuevo proyecto.

La solución a los problemas planteados anteriormente es la utilización de un archivo 'Dockerfile' para la construcción de nuestra imagen.
Un archivo 'Dockerfile' es básicamente un archivo de texto que describe de forma univoca cual es el contenido de la imagen. Para entenderlo mejor veamos como aplicaríamos esta técnica para la confección de la imagen del ejemplo anterior.
El contenido del archivo 'Dockerfile' sería el siguiente:

```
FROM ubuntu
AUTHOR ialmandos@conatel.com.uy
RUN apt-get update
RUN apt-get install -y python
RUN apt-get install -y python-pip
RUN pip install requests
RUN pip install libmysqlclient-dev MySQL-python
RUN apt-get install mysql-server
RUN apt-get install Django
RUN apt-get install tpftpd-hpa
RUN apt-get install open-ssh-server
```



## Comandos para revisar
---
```bash
docker images -a
docker history <nombre-de-la-imagen>
```
